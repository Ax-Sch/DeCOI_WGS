configfile: "config/config.yaml"

test_mode=["r","set"]
tests=["max"] #"skato" "sum",
PRSs=["PRS","regular"]
sex_params=["male","female","any"]
inheritance=["rec","add"]
filetypes=["anno.file", "aaf.file", "set.list"]

rule all:
	input:
		"results/PCA/populations_PCA.html",
		"results/primaryQC/sampleqc.tsv",
		"results/primaryQC/plot_sampleQC.html",
		"results/primaryQC/sexcheck.sexcheck",
		"results/primaryQC/sexcheck.jpg",
		"results/primaryQC/missingness.imiss",
		expand("results/GWAS/EUR_{pheno}.regenie.gz_LOG10P_manhattan.png", pheno=config["phenotypes"]),
		expand("results/GWAS/EUR_{pheno}_{subpheno}.regenie.gz_LOG10P_manhattan.png", pheno=config["phenotypes"], subpheno=["female","male", "GE60", "LT60","GE60CC", "LT60CC"]),
		expand("results/RVAS/{set}RVAS_{test}_EUR_POP_{pheno}_{PRS}/0.001_{pheno}.regenie.gzQQ.pdf", pheno=config["phenotypes"], test="max", set="r", PRS=PRSs),
		expand("results/RVAS/{set}RVAS_{test}_EUR_POP_{pheno}_{PRS}/0.001_{pheno}.regenie.gzQQ.pdf", pheno=config["phenotypes"], test=["sum","max"], set="set", PRS=PRSs),
		expand("results/RVAS/TLR7RVAS_EUR_POP_{pheno}_{PRS}/{rec}_{sex}_{pheno}.regenie.gzQQ.pdf", pheno=config["phenotypes"],rec=inheritance, PRS=PRSs, sex=sex_params),
		expand("results/RVAS/TLR7PlinkFisher/{sex}_{pheno}.model", pheno=config["phenotypes"], sex=sex_params),
		expand("results/RVAS/TLR7PlinkFisher/{sex}_{pheno}_cases.frqx", pheno=config["phenotypes"], sex=sex_params),
		"results/kinship/king.kin0",
		"results/GWAS/EUR:45859597_B1.regenie.gz",
		expand("results/GWAS/EUR:45859597_B1_{subpheno}.regenie.gz_LOG10P_manhattan.png", subpheno=["female","male", "GE60", "LT60"]),
		"results/PRS/scores.profile",
		"results/array_comparison/array_comp.con",
		expand("results/filtering/annotated_split_vep_{contig}.tsv", contig=config["contigs"]),
		expand("results/for_RVAS/{contig}.anno.file.txt", contig=config["contigs"]),
		expand("results/for_RVAS/all_contigs_{filetype}.txt", filetype=filetypes),
		config["database_dir"]+"/gnomad.genomes.v3.1.2.sites.all_red.vcf.gz",
		expand("results/vep/annotated_{contig}.vcf.gz", contig=config["contigs"]),
		expand("results/maf_comp/afs_{contig}.tsv.gz", contig=config["contigs"]),
		"results/bedfilesForPrefilter/ExonsClinVarSpliceAI.bed",
		expand("results/ROH/Plink/ROHAnalysis_ROH_{maf}_{pheno}.hom", maf=[0.01, 0], pheno=config["phenotypes"]),
		expand("results/ROH/Plink/INBAnalysis_ROH_{maf}_{pheno}.het.gz", maf=[0.01, 0], pheno=config["phenotypes"]),
		#expand("results/RVAS/{set}RVAS_{test}_EUR_POP_{pheno}_{PRS}/0.05_{pheno}.regenie.gzQQ.pdf", pheno=config["phenotypes"], test="skato", set=test_mode, PRS=PRSs),
		#expand("results/RVAS/plink_{set}RVAS/EUR_POP_{pheno}_{AF}_{pheno}.modelQQ.pdf", pheno=config["phenotypes"], AF=config["af_cutoffs"], set=test_mode),
		#"results/GWAS/EUR:45859597_B1.regenie.gz_LOG10P_manhattan.png",
		#"results/genomeScan/genomeScanEUR_A1G.fam",
		#"results/rvtests/results_Fisher/EUR_POP_A1/M3_0.01.CMCFisherExact.assoc",
		#"results/rvtests/results_SKAT_regional/EUR_POP_A1/M3_0.01.Skat.assoc",




# START # GENERAL QC ############################################################################################################################################

# normalize the vcf file and annotate it with the ID: CHROM:POS:REF:ALT
rule NormalizeBCF:
	input:
		bcf=config["input_bcf"],
		fasta=config["fasta"]
	output:
		vcf_gz="results/normalized/df3_norm.vcf.gz",
		vcf_gz_index="results/normalized/df3_norm.vcf.gz.tbi"
	resources: cpus=1, mem_mb=8000, time_job=10080
	params:
		partition=config["long"]
	conda: "envs/bcftools_plink_R.yaml"
	shell:
		"""
		#wget -nc ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz
		#gzip -d GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz
		bcftools filter -r chr1,chr2,chr3,chr4,chr5,chr6,chr7,chr8,chr9,chr10,chr11,chr12,chr13,chr14,chr15,chr16,chr17,chr18,chr19,chr20,chr21,chr22,chrX \
		  {input.bcf} -Ou | \
		  bcftools norm --check-ref w -f {input.fasta} -Ou | \
		  bcftools annotate --set-id '%CHROM:%POS:%REF:%FIRST_ALT' -Oz > {output.vcf_gz}
		tabix -p vcf {output.vcf_gz}
		"""


# Just calculate sample QC-data using hail
rule ConvertToHail:
	input:
		vcf="results/normalized/df3_norm.vcf.gz",
		individual_list="resources/.no_upload/covid_individuals.txt"
	output:
		hail_MT=directory("results/normalized/hail_MT"),
	resources: cpus=4, mem_mb=10000, time_job=10080, additional=" -x " + config["master_nodes_excluded"]
	params:
		partition=config["long"],
		tmp_dir=config["tmp_folder"],
	conda: "spark"
	shell:
		"""
		mkdir -p {params.tmp_dir}
		
		hail_python_script="workflow/scripts/vcf2hail.py $(pwd)/{input.vcf} \
		$(pwd)/{output} \
		$(pwd)/{params.tmp_dir} \
		$(pwd)/{input.individual_list}"
		
		if [ {config[cluster]} = "yes" ]; then
		worker_nodes_excluded={config[worker_nodes_excluded]}
		num_workers=60
		source workflow/scripts/spark_submit_command.sh
		$spark_submit_command $hail_python_script
		
		else
		python $hail_python_script
		fi
		"""

rule PrimaryQC:
	input:
		mt="results/normalized/hail_MT",
	output:		
		sample_qc_file="results/primaryQC/sampleqc.tsv",
		QC_fam="results/var_sets/for_QC/common.fam",
		QC_bed="results/var_sets/for_QC/common.bed",
		QC_bim="results/var_sets/for_QC/common.bim",
	resources: cpus=4, mem_mb=80000, time_job=720, additional=" --ntasks=1 " #-x " + config["master_nodes_excluded"] # --gres localtmp:300G
	params:
		partition=config["medium"],
		tmp_dir=config["tmp_folder"] +"prune_filter/",
		out_plink=lambda wildcards, output: output["QC_fam"][:-4],
	conda: "spark"
	shell:
		"""	
		mkdir -p {params.tmp_dir}
		
		hail_python_script="workflow/scripts/primaryQC.py \
		$(pwd)/{input.mt} \
		$(pwd)/{params.tmp_dir} \
		$(pwd)/{output.sample_qc_file} \
		$(pwd)/{params.out_plink}"
		
		if [ {config[cluster]} = "yes" ]; then
		queue="medium"
		export TMPDIR=$(pwd)/{params.tmp_dir}
		hours_to_run=12
		DRIVE_MEM=78
		SPARK_LOCAL_DIRS=$(pwd)/{params.tmp_dir}
		worker_nodes_excluded={config[worker_nodes_excluded]}
		num_workers=60
		source workflow/scripts/spark_submit_command.sh
		$spark_submit_command $hail_python_script
		
		else
		python $hail_python_script
		fi
		
		rm -rf {params.tmp_dir}*
		"""

rule ReformatPlotSampleQC:
	input:
		sampleQC="results/primaryQC/sampleqc.tsv",
		xl_file=config["pheno_excel"]
	output:
		"results/primaryQC/plot_sampleQC.html",
	resources: cpus=1, mem_mb=4000, time_job=720
	params:
		partition=config["medium"],
		path_output="results/primaryQC/"
	conda: "envs/bcftools_plink_R.yaml"
	shell:
		"""
		echo $(pwd)

		cp workflow/scripts/plot_sampleQC.R {params.path_output}
		cp {input.xl_file} {params.path_output}
		
		cd {params.path_output}
		
		Rscript -e 'library(rmarkdown); rmarkdown::render("plot_sampleQC.R", "html_document")'
		rm *.R
		"""

rule MakeVarSets:
	input:
		MT="results/normalized/hail_MT",
		individual_list="resources/.no_upload/Basic_QC_OK.txt",
		input_vcf="results/normalized/df3_norm.vcf.gz"
	output:
		fam="results/var_sets/general.fam",
		bim="results/var_sets/general.bim",
		bed="results/var_sets/general.bed",
		vcf="results/var_sets/general.vcf.bgz",
		famCommon="results/var_sets/common.fam",
		bimCommon="results/var_sets/common.bim",
		bedCommon="results/var_sets/common.bed",
		call_rate="results/var_sets/general_row_info.tsv.gz",
	resources: cpus=4, mem_mb=160000, time_job=1400, additional=" -x " + config["master_nodes_excluded"]
	params:
		partition=config["medium"],
		tmp_dir=config["tmp_folder"],
		out_trunk=lambda wildcards, output: output["fam"][:-4],
		out_Commontrunk=lambda wildcards, output: output["famCommon"][:-4],
	conda: "spark"
	shell:
		"""
		mkdir -p {params.tmp_dir}
		
		hail_python_script="workflow/scripts/MakeVarSets.py \
		$(pwd)/{params.tmp_dir} \
		$(pwd)/{input.MT} \
		$(pwd)/{input.input_vcf} \
		$(pwd)/{input.individual_list} \
		$(pwd)/{params.out_trunk} \
		$(pwd)/{params.out_Commontrunk}"
		
		if [ {config[cluster]} = "yes" ]; then
		export TMPDIR=$(pwd)/{params.tmp_dir}
		worker_nodes_excluded={config[worker_nodes_excluded]}
		hours_to_run=12
		DRIVE_MEM=148
		num_workers=60
		source workflow/scripts/spark_submit_command.sh
		$spark_submit_command $hail_python_script
		
		else
		python $hail_python_script
		fi
		"""


rule LDRegionsPrune:
	input:
		in_plink="results/var_sets/for_QC/common.fam",
		bed="resources/regions_of_high_LD_GRCh38.bed",
	output:		
		out_plink="results/var_sets/for_QC/common_pruned.fam",
		bim="results/var_sets/for_QC/common_pruned.bim",
		bed="results/var_sets/for_QC/common_pruned.bed",
	resources: cpus=4, mem_mb=16000, time_job=720, additional=" --ntasks=1 " #-x " + config["master_nodes_excluded"] # --gres localtmp:300G
	params:
		partition=config["medium"],
		in_plink=lambda wildcards, input: input["in_plink"][:-4],
		tmp_plink=lambda wildcards, output: output["out_plink"][:-4]+"_tmp",
		out_plink=lambda wildcards, output: output["out_plink"][:-4],
	conda: "envs/bcftools_plink_R.yaml"
	shell:
		"""
		plink2 \
		--bfile {params.in_plink} \
		--maf 0.01 \
		--exclude bed0 {input.bed} \
		--make-bed \
		--out {params.tmp_plink}		
		
		plink \
		--bfile {params.tmp_plink} \
		--indep-pairwise 1000kb 50 0.2 \
		--out {params.out_plink}
		
		plink \
		--bfile  {params.in_plink} \
		--extract {params.out_plink}.prune.in \
		--split-x hg38 no-fail \
		--make-bed \
		--out {params.out_plink}
		
		rm {params.tmp_plink}*
		"""


rule ImputeSex:
	input:
		fam="results/var_sets/for_QC/common_pruned.fam",
		bim="results/var_sets/for_QC/common_pruned.bim",
		bed="results/var_sets/for_QC/common_pruned.bed",
	output:		
		sex_check="results/primaryQC/sexcheck.sexcheck",
		hwe_vars="results/primaryQC/sexcheck.bim",
	resources: cpus=4, mem_mb=16000, time_job=720, additional=" --ntasks=1 " #-x " + config["master_nodes_excluded"] # --gres localtmp:300G
	params:
		partition=config["medium"],
		hwe_vars=lambda wildcards, output: output["hwe_vars"][:-4],
		out_plink=lambda wildcards, output: output["sex_check"][:-9],
	conda: "envs/bcftools_plink_R.yaml"
	shell:
		"""
		plink \
		--fam {input.fam} \
		--bim {input.bim} \
		--bed {input.bed} \
		--filter-females \
		--hwe 1e-3 midp include-nonctrl \
		--make-just-bim \
		--out {params.hwe_vars}

		plink \
		--fam {input.fam} \
		--bim {input.bim} \
		--bed {input.bed} \
		--extract {output.hwe_vars} \
		--check-sex 0.5 0.8 \
		--out {params.out_plink}

		"""

rule PlotImputedSex:
	input:
		"results/primaryQC/sexcheck.sexcheck",
	output:		
		"results/primaryQC/sexcheck.jpg"
	resources: cpus=1, mem_mb=4000, time_job=720, additional=" "
	params:
		partition=config["medium"],
	conda: "envs/bcftools_plink_R.yaml"
	script: "scripts/plotFcheckSex.R"


rule GetMissingness:
	input:
		fam="results/var_sets/for_QC/common_pruned.fam",
		bim="results/var_sets/for_QC/common_pruned.bim",
		bed="results/var_sets/for_QC/common_pruned.bed",
	output:		
		mind="results/primaryQC/missingness.imiss"
	resources: cpus=1, mem_mb=4000, time_job=720, additional=" "
	params:
		partition=config["medium"],
		out_plink=lambda wildcards, output: output["mind"][:-6],
	conda: "envs/bcftools_plink_R.yaml"
	shell:
		"""
		plink \
		--fam {input.fam} \
		--bim {input.bim} \
		--bed {input.bed} \
		--chr 1-22 \
		--missing \
		--out {params.out_plink}
		"""



#### Population PCA W 1000G project

rule Download_1000G_SampleInfo:
	output:
		#"GCA_000001405.15_GRCh38_no_alt_analysis_set.fna",
		"results/PCA/20130606_g1k.ped" # contig = chr1, ...
	resources: cpus=1, mem_mb=3000, time_job=720
	params:
		out_folder="results/PCA/",
		partition=config["medium"]
	shell:
		"""
		mkdir -p {params.out_folder}
		cd {params.out_folder}
		wget -nc ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/working/20130606_sample_info/20130606_g1k.ped
		
		#reference genome  (GRCh38)
		#wget -nc ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz
		#gzip -d GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz
		"""

rule Download_1000G_Genotypes:
	output:
		config["location_1000G"]+"ALL.chr{contig}.shapeit2_integrated_v1a.GRCh38.20181129.phased.vcf.gz",
		config["location_1000G"]+"ALL.chr{contig}.shapeit2_integrated_v1a.GRCh38.20181129.phased.vcf.gz.tbi"#
	resources: cpus=1, mem_mb=3000, time_job=720
	params:
		partition=config["medium"],
		folder_cont=config["location_1000G"]
	shell:
		"""
		mkdir -p {params.folder_cont}
		cd {params.folder_cont}
		prefix="ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/release/20181203_biallelic_SNV/ALL.chr"
		suffix=".shapeit2_integrated_v1a.GRCh38.20181129.phased.vcf.gz"
		wget -nc "$prefix""{wildcards.contig}""$suffix" "$prefix""{wildcards.contig}""$suffix".tbi
		"""


rule Prep_1000G_ForAncestryPCA:
	input:
		vcf=config["location_1000G"]+"ALL.chr{contig}.shapeit2_integrated_v1a.GRCh38.20181129.phased.vcf.gz",
		fasta=config["fasta"], #/ceph01/projects/bioinformatics_resources/Genomes/Human/GATK/hg38/Homo_sapiens_assembly38.fasta
		hailbim="results/var_sets/for_QC/common_pruned.bim",
	output:
		bcf="results/1000G/1000G_chr{contig}.bcf",
		bed2="results/1000G/1000G_chr{contig}_pruned.bed"
	resources: cpus=1, mem_mb=18000, time_job=720
	conda:
		"envs/bcftools_plink_R.yaml"
	params:
		partition=config["medium"],
		bed1="results/1000G/1000G_chr{contig}",
		bed2="results/1000G/1000G_chr{contig}_pruned"
	shell:
		"""
		if bcftools view -q 0.05:minor {input.vcf} | \
		bcftools norm -m-any --check-ref w -f "{input.fasta}" | \
		bcftools annotate -x ID -I +'%CHROM:%POS:%REF:%ALT' | \
		bcftools norm -Ob --rm-dup both \
		> {output.bcf} ; then
		echo "no error"
		fi
		
		plink --noweb \
		--bcf {output.bcf} \
		--keep-allele-order \
		--vcf-idspace-to _ \
		--allow-extra-chr 0 \
		--split-x b38 no-fail \
		--make-bed \
		--out {params.bed1}
		
		plink --noweb \
		--bfile {params.bed1} \
		--extract {input.hailbim} \
		--maf 0.10 --indep 50 5 1.5 \
		--make-bed \
		--out {params.bed2}
		"""
		
rule Merge_GTs_W_1000G_DoPCA:
	input:
		_1000G_data=expand("results/1000G/1000G_chr{contig}_pruned.bed", contig=config["contigs_wo_X"]), #### !!!!! 
		hailbim="results/var_sets/for_QC/common_pruned.bim",
		ped_file_1000G="results/PCA/20130606_g1k.ped"
	output:
		merge_list="results/1000G/merge_list.txt",
		bim_pca="results/PCA/MergeFullForPCA.bim",
		pca="results/PCA/MergeFullForPCA.eigenvec",
	resources: cpus=1, mem_mb=18000, time_job=720
	params:
		partition=config["medium"],
		hailplink=lambda wildcards, input: input["hailbim"][:-4],
		pca_prefix=lambda wildcards, output: output["bim_pca"][:-4],
	conda:
		"spark"
	shell:
		"""
		echo {input._1000G_data} | tr " " "\\n" | sed 's/.bed//g' > {output.merge_list}
		plink --merge-list {output.merge_list} --out results/1000G/Merged
		awk '{{ print $2 }}' results/1000G/Merged.bim > results/1000G/MergeVariants.txt
		
		plink --bfile {params.hailplink} \
		 --extract results/1000G/MergeVariants.txt \
		 --make-bed \
		 --out results/1000G/hail_for_ancestry
		 
		printf "results/1000G/Merged\\nresults/1000G/hail_for_ancestry" > results/1000G/ForMergeFull.list
		
		mkdir -p results/PCA
		plink --merge-list results/1000G/ForMergeFull.list --out results/PCA/MergeFullForPCA
		 
		awk '{{ print $1,$2 }}' results/1000G/Merged.fam | awk '$(NF+1) = "1000G"' > results/PCA/clusters.txt
		awk '{{ print $1,$2 }}' results/1000G/hail_for_ancestry.fam | awk '$(NF+1) = "Cohort"' >> results/PCA/clusters.txt
		
		plink --bfile results/PCA/MergeFullForPCA \
		 --pca-cluster-names 1000G \
		 --pca 20 \
		 --out {params.pca_prefix} \
		 --within results/PCA/clusters.txt
		"""


rule AnalysePCAResults:
	input:
		"results/PCA/MergeFullForPCA.eigenvec",
		"results/PCA/20130606_g1k.ped",
		"resources/.no_upload/covid_individuals.txt",
	output:
		populations="results/PCA/populations.txt",
		html="results/PCA/populations_PCA.html"
	resources: cpus=1, mem_mb=18000, time_job=720
	params:
		partition=config["medium"],
	conda:
		"envs/bcftools_plink_R.yaml"
	shell:
		"""
		cp -f workflow/scripts/populations_PCA.R results/PCA/populations_PCA.R
		cd results/PCA/
		Rscript -e 'library(rmarkdown); rmarkdown::render("populations_PCA.R", "html_document")'
		"""

rule KinshipAnalysis:
	input:
		fam="results/var_sets/for_QC/common_pruned.fam",
	output:
		kinship_file1="results/kinship/king.kin0",
	resources: cpus=4, mem_mb=16000, time_job=720, additional=" --ntasks=1 " #-x " + config["master_nodes_excluded"] # --gres localtmp:300G
	params:
		partition=config["medium"],
		plink_in=lambda wildcards, input: input["fam"][:-4],
		prefix=lambda wildcards, output: output["kinship_file1"][:-5],
	conda: "envs/king.yaml"
	shell:
		"""
		king \
		-b {params.plink_in}.bed \
		--kinship \
		--prefix {params.prefix}
		"""




rule SelectSubcohort:
	input:
		fam="results/var_sets/{set}.fam",
		bim="results/var_sets/{set}.bim",
		bed="results/var_sets/{set}.bed",
		list="resources/.no_upload/{subset}.tsv",
	output:
		fam="results/var_sets/{subset}/{set}.fam",
		bim="results/var_sets/{subset}/{set}.bim",
		bed="results/var_sets/{subset}/{set}.bed",
	resources: cpus=1, mem_mb=90000, time_job=720
	wildcard_constraints:
		set="[a-z]+",
		subset="[a-zA-Z0-9_]+",
	conda:
		"envs/bcftools_plink_R.yaml"
	params:
		partition=config["medium"],
		tmp_id="tmp/ind_ids{set}.txt",
		tmp_fam="tmp/tmp_fam{set}.fam",
		out_prefix=lambda wildcards, output: output["fam"][:-4]
	shell:
		"""
		cut -f1 {input.list} > {params.tmp_id}
		cat {input.fam} | grep -f {params.tmp_id} > {params.tmp_fam}
		
		plink \
		--bed {input.bed} \
		--bim {input.bim} \
		--fam {input.fam} \
		--keep {params.tmp_fam} \
		--make-bed \
		--out {params.out_prefix}
		"""

# END # GENERAL QC #############################################################################################################################################

# START # PHENO COVAR FILES #############################################################################################################################################


rule MakePhenoFileForGWAS:
	input:
		fam="results/var_sets/EURs_unrel/{set}.fam",
		bim="results/var_sets/EURs_unrel/{set}.bim",
		bed="results/var_sets/EURs_unrel/{set}.bed",
		individual_list="resources/.no_upload/EURs_unrel.tsv",
	output:
		fam="results/var_sets/EURs_unrel/{pheno}/{set}.fam",
		bim="results/var_sets/EURs_unrel/{pheno}/{set}.bim",
		bed="results/var_sets/EURs_unrel/{pheno}/{set}.bed",
		pheno="results/var_sets/EURs_unrel/{pheno}/{set}.pheno",
	resources: cpus=1, mem_mb=3000, time_job=720
	conda:
		"envs/bcftools_plink_R.yaml"
	wildcard_constraints:
		set="[a-z]+",
		pheno="A1|B1",
	params:
		partition=config["medium"],
		path="results/var_sets/EURs_unrel/{pheno}/"
	shell:
		"""
		mkdir -p {params.path} 
		Rscript workflow/scripts/generate_regenie_pheno.R {input.individual_list} {input.fam} {wildcards.pheno} {output.fam} {output.pheno}
		
		cp -f {input.bim} {output.bim}
		cp -f {input.bed} {output.bed}
		"""


rule AdditionalGWAS_SpecifcQC:
	input:
		fam="results/var_sets/EURs_unrel/{pheno}/common.fam",
		bim="results/var_sets/EURs_unrel/{pheno}/common.bim",
		bed="results/var_sets/EURs_unrel/{pheno}/common.bed",
	output:
		fam="results/var_sets/EURs_unrel/{pheno}/commonAdQC.fam",
		bim="results/var_sets/EURs_unrel/{pheno}/commonAdQC.bim",
		bed="results/var_sets/EURs_unrel/{pheno}/commonAdQC.bed",
	resources: cpus=6, mem_mb=90000, time_job=720, additional=" "
	params:
		partition=config["medium"],
		pathQC="tmp/QC_{pheno}/",
		out_prefix=lambda wildcards, output: output["fam"][:-4],
	conda: "envs/bcftools_plink_R.yaml"
	shell:
		"""
		mkdir -p {params.pathQC}
		plink \
		--bed {input.bed} \
		--bim {input.bim} \
		--fam {input.fam} \
		--filter-cases \
		--missing \
		--out {params.pathQC}/Geno05_CR_sex_snp_qc_snpqcCAS
		
		plink \
		--bed {input.bed} \
		--bim {input.bim} \
		--fam {input.fam} \
		--filter-controls \
		--missing \
		--out {params.pathQC}/Geno05_CR_sex_snp_qc_snpqcCON
		
		plink \
		--bed {input.bed} \
		--bim {input.bim} \
		--fam {input.fam} \
		--hardy \
		--out {params.pathQC}/Geno05_CR_sex_snp_qc_snpqcALL
				
		plink \
		--bed {input.bed} \
		--bim {input.bim} \
		--fam {input.fam} \
		--hardy \
		--chr 23 \
		--filter-females \
		--out {params.pathQC}/Geno05_CR_sex_snp_qc_snpqcALL_female

		### R session
		wd=$(pwd)
		cp workflow/scripts/additional_QC_cohort.R {params.pathQC}/
		cd {params.pathQC}
		Rscript -e 'library(rmarkdown); rmarkdown::render("additional_QC_cohort.R", "html_document")'
		cd $wd
		
		# 1e. final QC (4675116)
		plink \
		--bed {input.bed} \
		--bim {input.bim} \
		--fam {input.fam} \
		--exclude {params.pathQC}/missingness_hardy_weinberg_filter.txt \
		--make-bed \
		--out {params.out_prefix}

		rm -rf {params.pathQC}
		"""



rule MakePCA_CovarForGWAS:
	input:
		fam="results/var_sets/EURs_unrel/{pheno}/commonAdQC.fam",
		bim="results/var_sets/EURs_unrel/{pheno}/commonAdQC.bim",
		bed="results/var_sets/EURs_unrel/{pheno}/commonAdQC.bed",
	output:
		eigenv="results/var_sets/EURs_unrel/{pheno}/commonAdQC.eigenvec"
	resources: cpus=1, mem_mb=18000, time_job=720
	params:
		partition=config["medium"],
		folderPCA="results/var_sets/EURs_unrel/{pheno}/",
		pathinterim="results/var_sets/EURs_unrel/{pheno}/PCAtmp",
		out_prefix=lambda wildcards, output: output["eigenv"][:-9],
	conda: "envs/bcftools_plink_R.yaml"
	shell:
		"""
		mkdir -p {params.folderPCA}
		
		#common
		plink \
		--bed {input.bed} \
		--bim {input.bim} \
		--fam {input.fam} \
		--chr 1-22 \
		--indep-pairwise 50 5 0.05 \
		--keep-allele-order \
		--maf 0.01 \
		--out "{params.pathinterim}"

		plink \
		--bed {input.bed} \
		--bim {input.bim} \
		--fam {input.fam} \
		--extract "{params.pathinterim}.prune.in" \
		--pca 10 \
		--out "{params.out_prefix}"
		
		rm {params.pathinterim}*
		"""


rule MakeCovarFilesGWAS:
	input:
		PCA_cov="results/var_sets/EURs_unrel/{pheno}/commonAdQC.eigenvec",
		individual_list="resources/.no_upload/EURs_unrel.tsv"
	output:
		"results/var_sets/EURs_unrel/{pheno}/cov.cov"
	resources: cpus=1, mem_mb=3000, time_job=720
	params:
		partition=config["medium"],
	conda: "envs/bcftools_plink_R.yaml"
	shell:
		"""
		Rscript workflow/scripts/generate_covar_file.R {input.individual_list} {input.PCA_cov} {output}
		"""

rule CompilePhenoInfo:
	input:
		xl_file=config["pheno_excel"],
		qc_file="results/hail_gather_data/for_sample_QC.tsv"
	output:
		AgePlot="results/plotPhenoInfo/AgePlot.pdf",

	resources: cpus=1, mem_mb=6000, time_job=720, additional=" --ntasks=1 "
	params:
		partition=config["medium"],
		out_dir="results/plotPhenoInfo/",
	conda: "spark"
	shell:
		"Rscript workflow/scripts/compile_phenotype_plots.R {input} {params.out_dir}"



# END # PHENO COVAR FILES #############################################################################################################################################

# START # GWAS #############################################################################################################################################



rule RegenieStep2GWAS:
	input:
		cov="results/var_sets/EURs_unrel/{pheno}/cov.cov",
		pheno="results/var_sets/EURs_unrel/{pheno}/common.pheno",
		fam="results/var_sets/EURs_unrel/{pheno}/commonAdQC.fam",
		bim="results/var_sets/EURs_unrel/{pheno}/commonAdQC.bim",
		bed="results/var_sets/EURs_unrel/{pheno}/commonAdQC.bed",
	output:
		path_reg="results/GWAS/{population}_{pheno}.regenie.gz",
		path_reg_m="results/GWAS/{population}_{pheno}_male.regenie.gz",
		path_reg_f="results/GWAS/{population}_{pheno}_female.regenie.gz",
		path_reg_ge60="results/GWAS/{population}_{pheno}_GE60.regenie.gz",
		path_reg_lt60="results/GWAS/{population}_{pheno}_LT60.regenie.gz",
		path_reg_ge60cc="results/GWAS/{population}_{pheno}_GE60CC.regenie.gz",
		path_reg_lt60cc="results/GWAS/{population}_{pheno}_LT60CC.regenie.gz",
	resources: cpus=1, mem_mb=18000, time_job=720
	conda: "envs/regenie.yaml"
	params:
		partition=config["medium"],
		plink_file=lambda wildcards, input: input["fam"][:-4],
		regenie_step2=lambda wildcards, output: output["path_reg"][:-14]
	wildcard_constraints:
		population="EUR",
	shell:
		"""
		regenie \
		  --step 2 \
		  --minMAC 5 \
		  --covarFile {input.cov} \
		  --phenoFile {input.pheno} \
		  --bed {params.plink_file} \
		  --bt \
		  --ignore-pred \
		  --write-samples \
		  --bsize 5000 \
		  --out {params.regenie_step2} \
		  --af-cc \
		  --firth \
		  --firth-se \
		  --approx \
		  --gz
		  """


rule RegenieStep2GWAS_Conditional:
	input:
		cov="results/var_sets/EURs_unrel/{pheno}/cov.cov",
		pheno="results/var_sets/EURs_unrel/{pheno}/common.pheno",
		fam="results/var_sets/EURs_unrel/{pheno}/commonAdQC.fam",
		bim="results/var_sets/EURs_unrel/{pheno}/commonAdQC.bim",
		bed="results/var_sets/EURs_unrel/{pheno}/commonAdQC.bed",
		conditional_list="resources/{snp}.list",
	output:
		path_reg="results/GWAS/{population}:{snp}_{pheno}.regenie.gz",
		path_reg_m="results/GWAS/{population}:{snp}_{pheno}_male.regenie.gz",
		path_reg_f="results/GWAS/{population}:{snp}_{pheno}_female.regenie.gz",
		path_reg_ge60="results/GWAS/{population}:{snp}_{pheno}_GE60.regenie.gz",
		path_reg_lt60="results/GWAS/{population}:{snp}_{pheno}_LT60.regenie.gz",
		path_reg_ge60cc="results/GWAS/{population}:{snp}_{pheno}_GE60CC.regenie.gz",
		path_reg_lt60cc="results/GWAS/{population}:{snp}_{pheno}_LT60CC.regenie.gz",
	resources: cpus=1, mem_mb=18000, time_job=720
	conda: "envs/regenie.yaml"
	params:
		partition=config["medium"],
		plink_file=lambda wildcards, input: input["fam"][:-4],
		regenie_step2=lambda wildcards, output: output["path_reg"][:-14]
	shell:
		"""
		regenie \
		  --step 2 \
		  --minMAC 5 \
		  --covarFile {input.cov} \
		  --phenoFile {input.pheno} \
		  --bed {params.plink_file} \
		  --condition-list {input.conditional_list} \
		  --bt \
		  --ignore-pred \
		  --write-samples \
		  --bsize 5000 \
		  --out {params.regenie_step2} \
		  --af-cc \
		  --firth \
		  --firth-se \
		  --approx \
		  --gz
		  """

rule Plink2GWAS:
	input:
		cov="results/var_sets/EURs_unrel/{pheno}/cov.cov",
		fam="results/var_sets/EURs_unrel/{pheno}/commonAdQC.fam",
		bim="results/var_sets/EURs_unrel/{pheno}/commonAdQC.bim",
		bed="results/var_sets/EURs_unrel/{pheno}/commonAdQC.bed",
	output:
		plink_gwas="results/GWAS/{population}_{pheno}.PHENO1.glm.logistic"
	resources: cpus=1, mem_mb=18000, time_job=720
	conda: "envs/bcftools_plink_R.yaml"
	params:
		partition=config["medium"],
		plink_out=lambda wildcards, output: output["plink_gwas"][:-20]
	shell:
		"""
		plink2 \
		--bim {input.bim} \
		--bed {input.bed} \
		--fam {input.fam} \
		--glm no-x-sex hide-covar log10 \
		--covar {input.cov} \
		--covar-variance-standardize \
		--out {params.plink_out} \
		--mac 5
		  """


rule GenerateQQ_Plots:
	input:
		path_reg="results/GWAS/{infile}"
	output:
		"results/GWAS/{infile}_LOG10P_manhattan.png" 
	resources: cpus=1, mem_mb=20000, time_job=720
	params:
		partition=config["medium"],
	conda: "envs/bcftools_plink_R.yaml"
	shell:
		"""
		Rscript workflow/scripts/qqplots_GWAS.R -f {input} -o {input} -c CHROM -p LOG10P -b GENPOS --log TRUE -i ID
		"""



# END # GWAS #############################################################################################################################################

# START # RVAS #############################################################################################################################################

rule AddPRS_ToCovariates:
	input:
		"results/var_sets/EURs_unrel/{pheno}/cov.cov",
		"results/PRS/scores.profile"
	output:
		"results/var_sets/EURs_unrel/{pheno}/cov_PRS.cov",
	resources: cpus=1, mem_mb=4000, time_job=720
	params:
		partition=config["medium"]
	conda:
		"envs/bcftools_plink_R.yaml"
	script:
		"scripts/add_PRS_to_COV.R"



rule MakeGeneSetFilesRegenie:
	input:
		"resources/gene_sets.tsv",
		"resources/genomic_ranges.bed",
		"results/RVAS/data.anno.aaf.file.txt",
		"results/for_RVAS/all_contigs_anno.file.txt",
		"results/var_sets/EURs_unrel/general.bim",
	output:
		"results/RVAS/set.annos.tsv",
		"results/RVAS/set.aaf.tsv",
		"results/RVAS/set.sets.tsv",
		"results/RVAS/relevant_variants.tsv",
		"results/RVAS/set.vars.bim",
	resources: cpus=1, mem_mb=40000, time_job=720
	params:
		partition=config["medium"]
	conda:
		"envs/bcftools_plink_R.yaml"
	script:
		"scripts/gene_sets.R"

rule AllGeneSetVarsOnArtificialChrom:
	input:
		fam="results/var_sets/EURs_unrel/{pheno}/general.fam",
		bed="results/var_sets/EURs_unrel/{pheno}/general.bed",
		bim="results/RVAS/set.vars.bim",
		relevant_vars="results/RVAS/relevant_variants.tsv",
	output:
		fam="results/var_sets/EURs_unrel/{pheno}/general_oneChr.fam",
		bed="results/var_sets/EURs_unrel/{pheno}/general_oneChr.bed",
		bim="results/var_sets/EURs_unrel/{pheno}/general_oneChr.bim",
	resources: cpus=1, mem_mb=40000, time_job=720
	conda: "envs/bcftools_plink_R.yaml"
	params:
		partition=config["medium"],
		plink_file=lambda wildcards, input: input["bed"][:-4],
		plink_out=lambda wildcards, output: output["bed"][:-4]
	shell:
		"""
		plink \
		--fam {input.fam} \
		--bed {input.bed} \
		--bim {input.bim} \
		--extract {input.relevant_vars} \
		--make-bed \
		--out {params.plink_out}
		"""


rule PrefilterPlinkForAF:
	input:
		fam="{plink}.fam",
		bed="{plink}.bed",
		bim="{plink}.bim",
	output:
		fam="{plink}_{AF}.fam",
		bed="{plink}_{AF}.bed",
		bim="{plink}_{AF}.bim",
	resources: cpus=1, mem_mb=40000, time_job=720
	conda: "envs/bcftools_plink_R.yaml"
	wildcard_constraints:
		AF="0.*[0-9]"
	params:
		partition=config["medium"],
		plink_file=lambda wildcards, input: input["bed"][:-4],
		plink_out=lambda wildcards, output: output["bed"][:-4]
	shell:
		"""
		plink \
		--fam {input.fam} \
		--bed {input.bed} \
		--bim {input.bim} \
		--max-maf {wildcards.AF} \
		--make-bed \
		--out {params.plink_out}
		"""


rule RegenieStep2_RVAS_SUM_SKAT:
	input:
		cov=lambda wildcards: "results/var_sets/EURs_unrel/{pheno}/cov_PRS.cov" if (wildcards["PRS"]=="PRS") else "results/var_sets/EURs_unrel/{pheno}/cov.cov",
		pheno="results/var_sets/EURs_unrel/{pheno}/common.pheno",
		mask_def="resources/mask_definition.mask", #lambda wildcards: "resources/mask_definition.mask" if (wildcards["set"]=="r") else "resources/mask_definitionRegional.mask",
		plink_file=lambda wildcards: "results/var_sets/EURs_unrel/{pheno}/general_{AF}.bed" if (wildcards["set"]=="r") else "results/var_sets/EURs_unrel/{pheno}/general_oneChr_{AF}.bed",
		anno_csq=lambda wildcards: "results/for_RVAS/all_contigs_anno.file.txt" if (wildcards["set"]=="r") else "results/RVAS/set.annos.tsv",
                anno_aaf=lambda wildcards: "results/RVAS/data.anno.aaf.file.txt" if (wildcards["set"]=="r") else "results/RVAS/set.aaf.tsv",
		var_sets=lambda wildcards: "results/for_RVAS/all_contigs_set.list.txt" if (wildcards["set"]=="r") else "results/RVAS/set.sets.tsv",
	output:
		path_reg="results/RVAS/{set}RVAS_{test}_{population}_POP_{pheno}_{PRS}/{AF}_{pheno}.regenie.gz",
	resources: cpus=1, mem_mb=72000, time_job=2880
	wildcard_constraints:
		test="sum|skato|max",
		PRS="PRS|regular",
	conda: "envs/regenie.yaml"
	params:
		partition=config["medium"],
		plink_file=lambda wildcards, input: input["plink_file"][:-4],
		regenie_step2=lambda wildcards, output: output["path_reg"][:-14],
		test_params=lambda wildcards: "--build-mask sum --firth --firth-se " if wildcards["test"]=="sum" else ("--vc-tests skato --vc-maxAAF "+ wildcards["AF"] + " --vc-MACthr 10 " if wildcards["test"]=="skato" else "--build-mask max --firth --firth-se "),
	shell:
		"""
		export LD_LIBRARY_PATH={config[LD_LIBRARY_PATH]}

		regenie \
		  --step 2 \
		  --minMAC 1 \
		  --covarFile {input.cov} \
		  --phenoFile {input.pheno} \
		  --aaf-file {input.anno_aaf} \
		  --anno-file {input.anno_csq} \
		  --mask-def {input.mask_def} \
		  --set-list {input.var_sets} \
		  --bed {params.plink_file} \
		  --aaf-bins {wildcards.AF} \
		  --bt \
		  --write-samples \
		  --ignore-pred \
		  --out {params.regenie_step2} \
		  {params.test_params} \
		  --af-cc \
		  --maxstep-null 2 \
		  --maxiter-null 100000 \
		  --gz

		  #--check-burden-files \
		  #--strict-check-burden \
		"""



rule PlinkFisher:
	input:
		mask_bed="results/RVAS/{set}RVAS_{population}_POP_{pheno}_{AF}_masks.bed",
		fam="results/var_sets/EURs_unrel/{pheno}/general.fam",
		mask_bim="results/RVAS/{set}RVAS_{population}_POP_{pheno}_{AF}_masks.bim",
	output:
		fisher="results/RVAS/plink_{set}RVAS/{population}_POP_{pheno}_{AF}_{pheno}.model",
	resources: cpus=1, mem_mb=18000, time_job=720
	conda: "envs/bcftools_plink_R.yaml"
	params:
		partition=config["medium"],
		plink_in=lambda wildcards, input: input["mask_bed"][:-4],
		plink_out=lambda wildcards, output: output["fisher"][:-6]
	shell:
		"""
		plink \
		--fam {input.fam} \
		--bim {input.mask_bim} \
		--bed {input.mask_bed} \
		--model fisher \
		--out {params.plink_out}
		"""

rule QQ_PlotsRVAS:
	input:
		"{prefix}",
		"resources/ENSG_to_name.txt"
	output:
		"{prefix}QQ.pdf"
	resources: cpus=1, mem_mb=32000, time_job=720
	params:
		burden_test="TRUE",
		partition=config["medium"]
	conda:
		"envs/bcftools_plink_R.yaml"
	script:
		"scripts/qq_plots_RVAS.R"


# END # RVAS #############################################################################################################################################

# START # PRS #############################################################################################################################################


rule CalculateIndividualPRS:
	input:
		famCommon="results/var_sets/common.fam",
		bimCommon="results/var_sets/common.bim",
		bedCommon="results/var_sets/common.bed",
		PRS="resources/.no_upload/PRSconcat.tsv", # note: this file was modified to contain the variant IDs as used in the bim file
	output:		
		scores="results/PRS/scores.profile"
	resources: cpus=1, mem_mb=32000, time_job=720, additional=" "
	params:
		partition=config["medium"],
		out_pref="results/PRS/scores",
	conda: "envs/bcftools_plink_R.yaml"
	shell:
		"""
		plink \
		--fam {input.famCommon} \
		--bim {input.bimCommon} \
		--bed {input.bedCommon} \
		--score {input.PRS} 1 2 3 sum \
		--out {params.out_pref}
		"""


# END # PRS #############################################################################################################################################


# START # TLR7 ##########################################################################################################################################

rule FilterTLR7_Region:
	input:
		fam="results/var_sets/EURs_unrel/{pheno}/general.fam",
		bim="results/var_sets/EURs_unrel/{pheno}/general.bim",
		bed="results/var_sets/EURs_unrel/{pheno}/general.bed",
	output:		
		fam="results/var_sets/EURs_unrel/{pheno}/generalTLR7.fam",
		bim="results/var_sets/EURs_unrel/{pheno}/generalTLR7.bim",
		bed="results/var_sets/EURs_unrel/{pheno}/generalTLR7.bed",
	resources: cpus=1, mem_mb=32000, time_job=720, additional=" "
	params:
		partition=config["medium"],
		out_plink=lambda wildcards, output: output["bed"][:-4],
	conda: "envs/bcftools_plink_R.yaml"
	shell:
		"""
		plink \
		--fam {input.fam} \
		--bim {input.bim} \
		--bed {input.bed} \
		--chr X \
		--from-bp 12767072 \
		--to-bp 12967072 \
		--make-bed \
		--out {params.out_plink}
		"""


rule RegenieStep2_TLR7:
	input:
		cov=lambda wildcards: "results/var_sets/EURs_unrel/{pheno}/cov_PRS.cov" if (wildcards["PRS"]=="PRS") else "results/var_sets/EURs_unrel/{pheno}/cov.cov",
		pheno="results/var_sets/EURs_unrel/{pheno}/common.pheno",
		plink_file="results/var_sets/EURs_unrel/{pheno}/generalTLR7.bed",
	output:
		path_reg="results/RVAS/TLR7RVAS_EUR_POP_{pheno}_{PRS}/{rec}_{sex}_{pheno}.regenie.gz",
	resources: cpus=1, mem_mb=72000, time_job=2880
	wildcard_constraints:
		PRS="PRS|regular",
		sex="male|female|any",
	conda: "envs/regenie.yaml"
	params:
		partition=config["medium"],
		plink_file=lambda wildcards, input: input["plink_file"][:-4],
		regenie_step2=lambda wildcards, output: output["path_reg"][:-14],
		rez=lambda wildcards: "--test recessive" if wildcards["rec"]=="rec" else "",
		sex_param=lambda wildcards: " --sex-specific " + wildcards["sex"] + " --phenoCol " + wildcards["pheno"] if wildcards["sex"]!="any" else "",
	shell:
		"""
		export LD_LIBRARY_PATH={config[LD_LIBRARY_PATH]}

		regenie \
		  --step 2 \
		  --minMAC 1 \
		  --covarFile {input.cov} \
		  --phenoFile {input.pheno} \
		  --bed {params.plink_file} \
		  --bt \
		  --firth \
		  --firth-se \
		  --write-samples \
		  --ignore-pred \
		  --out {params.regenie_step2} \
		  {params.rez} \
		  {params.sex_param} \
		  --af-cc \
		  --bsize 500 \
		  --gz
		"""


rule TLR7PlinkFisher:
	input:
		fam="results/var_sets/EURs_unrel/{pheno}/generalTLR7.fam",
		bim="results/var_sets/EURs_unrel/{pheno}/generalTLR7.bim",
		bed="results/var_sets/EURs_unrel/{pheno}/generalTLR7.bed",
	output:
		fisher="results/RVAS/TLR7PlinkFisher/{sex}_{pheno}.model",
	resources: cpus=1, mem_mb=18000, time_job=720
	conda: "envs/bcftools_plink_R.yaml"
	wildcard_constraints:
		sex="male|female|any",
	params:
		partition=config["medium"],
		plink_out=lambda wildcards, output: output["fisher"][:-6],
		sex_param=lambda wildcards: "--filter-females" if wildcards["sex"]=="female" else ("--filter-males" if wildcards["sex"]=="male" else ""),
	shell:
		"""
		plink \
		--fam {input.fam} \
		--bim {input.bim} \
		--bed {input.bed} \
		{params.sex_param} \
		--model fisher \
		--out {params.plink_out}
		"""

rule TLR7PlinkCounts:
	input:
		fam="results/var_sets/EURs_unrel/{pheno}/generalTLR7.fam",
		bim="results/var_sets/EURs_unrel/{pheno}/generalTLR7.bim",
		bed="results/var_sets/EURs_unrel/{pheno}/generalTLR7.bed",
	output:
		cases="results/RVAS/TLR7PlinkFisher/{sex}_{pheno}_cases.frqx",
		controls="results/RVAS/TLR7PlinkFisher/{sex}_{pheno}_controls.frqx",
	resources: cpus=1, mem_mb=18000, time_job=720
	conda: "envs/bcftools_plink_R.yaml"
	wildcard_constraints:
		sex="male|female|any",
	params:
		partition=config["medium"],
		out_case=lambda wildcards, output: output["cases"][:-5],
		out_ctrl=lambda wildcards, output: output["controls"][:-5],
		sex_param=lambda wildcards: "--filter-females" if wildcards["sex"]=="female" else ("--filter-males" if wildcards["sex"]=="male" else ""),
	shell:
		"""
		plink \
		--fam {input.fam} \
		--bim {input.bim} \
		--bed {input.bed} \
		{params.sex_param} \
		--filter-cases \
		--freqx \
		--out {params.out_case}
		
		plink \
		--fam {input.fam} \
		--bim {input.bim} \
		--bed {input.bed} \
		{params.sex_param} \
		--filter-controls \
		--freqx \
		--out {params.out_ctrl}		
		"""

# END # TLR7 ############################################################################################################################################


# START # ROH #############################################################################################################################################


rule ROH_Plink:
	input:
		fam="results/var_sets/EURs_unrel/{pheno}/general.fam",
		bed="results/var_sets/EURs_unrel/{pheno}/general.bed",
		bim="results/var_sets/EURs_unrel/{pheno}/general.bim",
	output:
		ROH_file=multiext("results/ROH/Plink/ROHAnalysis_ROH_{maf}_{pheno}", ".hom", ".hom.indiv", ".hom.summary", ".log")
	conda: "envs/bcftools_plink_R.yaml"
	resources: cpus=4, mem_mb=80000, time_job=2000
	params:
		partition=config["medium"],
		ROH_out="results/ROH/Plink/ROHAnalysis_ROH_{maf}_{pheno}",
		maf=lambda wildcards: "" if wildcards["maf"] == "0" else "--maf "+ wildcards["maf"],
	shell:
		"""
		plink \
		--fam {input.fam} \
		--bed {input.bed} \
		--bim {input.bim} \
		{params.maf} \
		--homozyg \
		--out {params.ROH_out}
		"""

rule InbreedingPlink:
	input:
		fam="results/var_sets/EURs_unrel/{pheno}/general.fam",
		bed="results/var_sets/EURs_unrel/{pheno}/general.bed",
		bim="results/var_sets/EURs_unrel/{pheno}/general.bim",
	output:
		ROH_file="results/ROH/Plink/INBAnalysis_ROH_{maf}_{pheno}.het.gz"
	conda: "envs/Plink.yaml"
	resources: cpus=4, mem_mb=80000, time_job=2000
	params:
		partition=config["medium"],
		ROH_out=lambda wildcards, output: output["ROH_file"][:-7],
	shell:
		"""
		plink \
		--fam {input.fam} \
		--bed {input.bed} \
		--bim {input.bim} \
		--het gz \
		--ibc \
		--out {params.ROH_out}
		"""


# END # ROH #############################################################################################################################################


# START # ANNOTATION ####################################################################################################################################


rule DownloadGnomAD:
	output:
		config["database_dir"]+"/gnomad.genomes.v3.1.2.sites.chr{contig}.vcf.bgz"
	params: 
		partition=config["long"],
		out_folder=config["database_dir"]
	resources: cpus=1, mem_mb=4000, time_job=10000
	shell: 
		"""
		cd {params.out_folder}
		wget https://storage.googleapis.com/gcp-public-data--gnomad/release/3.1.2/vcf/genomes/gnomad.genomes.v3.1.2.sites.chr{wildcards.contig}.vcf.bgz
		wget https://storage.googleapis.com/gcp-public-data--gnomad/release/3.1.2/vcf/genomes/gnomad.genomes.v3.1.2.sites.chr{wildcards.contig}.vcf.bgz.tbi
		"""

rule DownloadCADD:
	output:
		config["database_dir"]+"/whole_genome_SNVs.tsv.gz"
	params: 
		partition=config["long"],
		out_dir=config["database_dir"]
	resources: cpus=1, mem_mb=10, time_job=10000
	shell:
		"""
		cd {params.out_dir}
		wget https://kircherlab.bihealth.org/download/CADD/v1.6/GRCh38/whole_genome_SNVs.tsv.gz
		wget https://kircherlab.bihealth.org/download/CADD/v1.6/GRCh38/whole_genome_SNVs.tsv.gz.tbi
		wget https://kircherlab.bihealth.org/download/CADD/v1.6/GRCh38/gnomad.genomes.r3.0.snv.tsv.gz
		wget https://kircherlab.bihealth.org/download/CADD/v1.6/GRCh38/gnomad.genomes.r3.0.snv.tsv.gz.tbi
		"""



rule ReduceGnomAD:
	input:
		config["database_dir"]+"/gnomad.genomes.v3.1.2.sites.chr{contig}.vcf.bgz"
	output:
		config["database_dir"]+"/gnomad.genomes.v3.1.2.sites.chr{contig}_red.vcf.gz"
	params: partition=config["long"]
	resources: cpus=1, mem_mb=4000, time_job=10000
	conda:
		"envs/bcftools_plink_R_bedtools.yaml"

	shell:
		"""
		keep_string="^INFO/AC,INFO/AN,INFO/AF,INFO/popmax,INFO/faf95_popmax,INFO/AC_oth,INFO/AN_oth,INFO/AF_oth,INFO/nhomalt_oth,INFO/AC_ami,INFO/AN_ami,INFO/AF_ami,INFO/nhomalt_ami,INFO/AC_sas,INFO/AN_sas,INFO/AF_sas,INFO/nhomalt_sas,INFO/AC_fin,INFO/AN_fin,INFO/AF_fin,INFO/nhomalt_fin,INFO/AC_eas,INFO/AN_eas,INFO/AF_eas,INFO/nhomalt_eas,INFO/AC_amr,INFO/AN_amr,INFO/AF_amr,INFO/nhomalt_amr,INFO/AC_afr,INFO/AN_afr,INFO/AF_afr,INFO/nhomalt_afr,INFO/AC_raw,INFO/AN_raw,INFO/AF_raw,INFO/nhomalt_raw,INFO/AC_mid,INFO/AN_mid,INFO/AF_mid,INFO/nhomalt_mid,INFO/nhomalt,INFO/AC_asj,INFO/AN_asj,INFO/AF_asj,INFO/nhomalt_asj,INFO/AC_nfe,INFO/AN_nfe,INFO/AF_nfe,INFO/nhomalt_nfe,INFO/AC_popmax,INFO/AN_popmax,INFO/AF_popmax,INFO/nhomalt_popmax"
		bcftools annotate -x "$keep_string" {input} -Oz -o {output}
		
		tabix -pvcf {output}
		#rm {input}
		"""

rule CombineGnomAD_Contigs:
	input:
		expand(config["database_dir"]+"/gnomad.genomes.v3.1.2.sites.chr{contig}_red.vcf.gz", contig=config["contigs"])
	output:
		reduced=config["database_dir"]+"/gnomad.genomes.v3.1.2.sites.all_red.vcf.gz",
		#above_one_perc=config["database_dir"]+"/gnomad.genomes.v3.1.1.sites.all_red_more_freq_than_percent.vcf.gz"
	params: partition=config["medium"]
	resources: cpus=1, mem_mb=4000, time_job=720
	conda:
		"envs/bcftools_plink_R_bedtools.yaml"
	shell:
		"""
		bcftools concat -Oz {input} > {output.reduced}
		tabix -pvcf {output.reduced}
		#bcftools view ouptut.reduced -i "INFO/AF>0.01" -Oz -o output.above_one_perc
		#tabix -pvcf output.above_one_perc
		"""


rule GetBedOfRelevantRegions:
	input:
		DHS="resources/DHS_Index_and_Vocabulary_hg38_WM20190703.core.bed.gz",
		GenRa="resources/genomic_ranges.bed",
	output:
		"results/bedfilesForPrefilter/ExonsClinVarSpliceAI.bed"
	params: partition=config["medium"],
		out_folder="results/bedfilesForPrefilter",
		anno_sources=config["database_dir"],
	resources: cpus=1, mem_mb=9000, time_job=720
	conda:
		"envs/bcftools_plink_R_bedtools.yaml"
	shell:
		"""
		# software required: bedops, bedtools
		mkdir -p {params.out_folder}
		cd {params.out_folder}

		# get bedtools reference file
		wget -Nc https://raw.githubusercontent.com/arq5x/bedtools2/master/genomes/human.hg38.genome -O bedtools_hg38_ref_file.genome

		# GENCODE
		wget -Nc ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_35/gencode.v35.annotation.gff3.gz

		# exons
		zcat gencode.v35.annotation.gff3.gz | \
		 awk '$3 == "exon"' - | \
		 sort -k1,1 -k4,4n -V | \
		 bedtools merge -i stdin | \
		 cut -f1-3 | gzip > gencode35Exons.bed.gz

		# add padding to gencode file
		bedtools slop -b 20 \
		-i gencode35Exons.bed.gz \
		-g bedtools_hg38_ref_file.genome | \
		gzip > gencode35ExonsPadded.bed.gz

		# promoters
		zcat gencode.v35.annotation.gff3.gz | \
		grep -P "transcript\t" | grep -P "\t\+\t" | \
		 awk '{{OFS="\t"}}{{print $1,$4-1001,$4-1}}' > plus_strand_promotor.bed
		
		zcat gencode.v35.annotation.gff3.gz | \
		grep -P "transcript\t" | grep -P "\t\-\t" | \
		awk '{{OFS="\t"}}{{print $1,$5-1,$5+999}}' > minus_strand_promotor.bed

		cat plus_strand_promotor.bed minus_strand_promotor.bed | \
		sort -k1,1 -k3,3n -V | \
		awk '{{OFS="\t"}}{{if ($2<0) print $1,"0",$3; else print $0}}' | \
		gzip > promoters.bed.gz
		

		# ClinVar
		wget -Nc ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh38/clinvar.vcf.gz
		zcat clinvar.vcf.gz | grep "^#"  > clinvar_pathogenic.vcf
		zcat clinvar.vcf.gz | grep -v "^#" | egrep "pathogenic|Pathogenic" | grep -v "uncertain" >> clinvar_pathogenic.vcf
		bedtools merge -i clinvar_pathogenic.vcf | cut -f1-3 | awk '{{OFS=""}}{{print "chr",$0}}' | gzip > clinvar_pathogenic.bed.gz

		# SpliceAI
		# filter splice AI for scores >0.5 and convert to BED
		zcat {params.anno_sources}'/spliceai_scores_sorted.hg38.vcf.gz' | \
		egrep "0\.[5-9]|1\.0" | \
		awk 'BEGIN {{OFS="\t"}} {{ print $1, $2-1, $2 }}' | \
		gzip > \
		splice_ai_positions.bed.gz


		# merge and sort individual bed files
		zcat gencode35ExonsPadded.bed.gz clinvar_pathogenic.bed.gz splice_ai_positions.bed.gz promoters.bed.gz ../../{input.DHS} | \
		cat - ../../{input.GenRa} | \
		cut -f1-3 | \
		bedtools sort | \
		bedtools merge > "ExonsClinVarSpliceAI.bed"
		"""



rule PrefilterBcf_w_Bed:
	input:
		bcf=config["input_bcf"],
		bedfile="results/bedfilesForPrefilter/ExonsClinVarSpliceAI.bed"
	output:
		vcf_prefiltered="results/prefilter/all_samples_genome_prefiltered_{contig}.vcf.gz",
		relevant_bed="results/prefilter/bed_{contig}.bed"
	params:
		partition="long"
	resources: cpus=1, mem_mb=4000, time_job=7200, additional=""
	conda:
		"envs/bcftools_plink_R_bedtools.yaml"
	shell:
		"""
		cat {input.bedfile} | grep "^chr{wildcards.contig}	" > {output.relevant_bed}
		
		bcftools view {input} -R {output.relevant_bed} -Ob | \
		bcftools sort -T $TMPDIR | \
		bcftools norm -m-any -Ob | \
		bcftools norm --remove-duplicates -Oz -o {output.vcf_prefiltered}
		"""

rule VEP_Annotation:
	input:
		vcf="results/prefilter/all_samples_genome_prefiltered_{contig}.vcf.gz",
		DHS="resources/DHS_Index_and_Vocabulary_hg38_WM20190703.core.bed.gz",
	output:
		"results/vep/annotated_{contig}.vcf.gz"
	params:
		partition=config["long"],
		anno_sources=config["database_dir"],
		buffer=2000
	conda:
		"envs/vep_101.yaml"
	resources: cpus=4, mem_mb=50000, time_job=10040, additional=" "
	shell:
		"""

		work_dir=$(pwd)
		database_dir={params.anno_sources}
		
		echo $SLURM_NODELIST			
		echo $TMPDIR
		
		cd $TMPDIR
		#git clone https://github.com/ImperialCardioGenetics/UTRannotator.git
		#export PERL5LIB=$(pwd)/UTRannotator
		cp -v $database_dir'/Homo_sapiens_assembly38.fasta.bgz'* . #/dev/shm/ #1G, store to RAMdisk
		cp -v $database_dir'/gnomad.genomes.v3.1.2.sites.all_red.vcf.gz'* . # 9G
		#cp -v $database_dir'/gnomad.exomes.r2.1.1.sites.liftover_grch38.vcf.bgz'* . # 86 G biggest file, do not copy
		mkdir -p dbNSFP41
		cp -v $database_dir'/dbNSFP41/dbNSFP4.1a_hg38.gz'* dbNSFP41/ #31G
		cp -v $database_dir'/dbNSFP41/dbNSFP4.1a.readme.txt' dbNSFP41/
		cp -v $database_dir'/spliceai_scores_sorted.hg38.vcf.gz'* . #0,6G
		cp -v $database_dir'/cnv_database_171_samples.vcf.gz'* .
		#cp -v $database_dir'/whole_genome_SNVs.tsv.gz'* . # copy CADD 81G
		#cp -v $database_dir'/gnomad.genomes.r3.0.snv.tsv.gz'* . # copy CADD 6G
		cp -rv $database_dir'/homo_sapiens' . # 15G
		wget -N ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh38/clinvar.vcf.gz  
		wget -N ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh38/clinvar.vcf.gz.tbi	
		
		cd $work_dir
		
		#export PERL5LIB=$database_dir'/UTRannotator/'
		#wget https://raw.githubusercontent.com/Ensembl/VEP_plugins/postreleasefix/101/TSSDistance.pm
		export PERL5LIB=$database_dir

		vep -v  \
		--cache \
		--offline \
		--force_overwrite \
		--fork 8 \
		--buffer {params.buffer} \
		--hgvs \
		--no_stats \
		--format vcf \
		--numbers \
		--nearest gene \
		--vcf \
		--distance 50000,1000 \
		--gene_phenotype \
		--pick_allele_gene \
		--af \
		--af_esp \
		--check_existing \
		-a GRCh38 \
		--dir_cache $TMPDIR \
		--fasta $TMPDIR'/Homo_sapiens_assembly38.fasta.bgz' \
		--custom $TMPDIR'/clinvar.vcf.gz',ClinVar,vcf,exact,0,CLNSIG,CLNREVSTAT,CLNDN \
		--custom $TMPDIR'/gnomad.genomes.v3.1.2.sites.all_red.vcf.gz',gnomAD_ge,vcf,exact,0,AF,AC,AN,nhomalt,popmax,AF_oth,AF_ami,AF_sas,AF_fin,AF_eas,AF_amr,AF_afr,nhomalt_afr,AF_raw,AF_mid,AF_asj,AF_nfe,AF_popmax \
		--custom $database_dir'/gnomad.exomes.r2.1.1.sites.liftover_grch38.vcf.bgz',gnomAD_ex,vcf,exact,0,AF,AN,AC,AF_afr,AF_amr,AF_asj,AF_eas,AF_fin,AF_nfe,AF_oth,AF_sas,nhomalt \
		--plugin dbNSFP,$TMPDIR'/dbNSFP41/dbNSFP4.1a_hg38.gz',Ensembl_proteinid,MutationTaster_pred,MutationTaster_score,LRT_pred,Polyphen2_HDIV_pred,Polyphen2_HVAR_pred,SIFT_pred,REVEL_score,REVEL_rankscore,phyloP100way_vertebrate,phyloP100way_vertebrate_rankscore,phastCons100way_vertebrate,phastCons100way_vertebrate_rankscore,BayesDel_noAF_score,BayesDel_noAF_pred \
		--plugin CADD,$database_dir'/whole_genome_SNVs.tsv.gz',$database_dir'/gnomad.genomes.r3.0.snv.tsv.gz' \
		--custom $TMPDIR'/spliceai_scores_sorted.hg38.vcf.gz',SpliceAI,vcf,exact,0,ALLELE,SYMBOL,DS_AG,DS_AL,DS_DG,DS_DL  \
		--custom {input.DHS},DHS,bed,exact,0 \
		--plugin StructuralVariantOverlap,file=$TMPDIR'/cnv_database_171_samples.vcf.gz' \
		--plugin TSSDistance \
		-i {input.vcf} \
		-o stdout | bgzip > {output}
		
		#--plugin UTRannotator,$TMPDIR'/UTRannotator/uORF_starts_ends_GRCh38_PUBLIC.txt' \
		#--custom $TMPDIR'/gnomad.exomes.r2.1.1.sites.liftover_grch38.vcf.bgz',gnomAD_ex,vcf,exact,0,AF,AN,AC,AF_afr,AF_amr,AF_asj,AF_eas,AF_fin,AF_nfe,AF_oth,AF_sas,nhomalt \
		
		#rm /dev/shm/Homo_sapiens_assembly38.fasta.bgz*
		
		"""


rule PrefilterVEP_ForManualAnalysis:
	input:
		"results/vep/annotated_{contig}.vcf.gz"
	output:
		"results/filtering/annotated_split_vep_{contig}.vcf.gz"
	params:
		partition=config["long"],
		vep_filtered="results/filtering/annotated_filtered_{contig}.vcf",
		vep_renamed="results/filtering/annotated_filtered_renamed_{contig}.vcf",
		anno_sources=config["database_dir"],
	conda:
		"envs/vep_101.yaml"
	resources: cpus=1, mem_mb=9000, time_job=10040
	shell:
		"""
		function return_AF_string_w_genomes
		{{
		echo "((gnomAD_ge_AF < "$1" or not gnomAD_ge_AF) and ((IMPACT is HIGH) or (IMPACT is MODERATE) or (IMPACT is LOW) or (SpliceAI_SYMBOL)) and (gnomAD_ge_nhomalt < 11 or not gnomAD_ge_nhomalt)) or (ClinVar_CLNSIG and not (ClinVar_CLNSIG match benign or ClinVar_CLNSIG match Benign)) or (CLIN_SIG match pathogenic or CLIN_SIG match Pathogenic)"
		
		#echo "((gnomAD_ge_AF_AFR < "$1" or not gnomAD_ge_AF_AFR) and (gnomAD_ge_AF_AMR < "$1" or not gnomAD_ge_AF_AMR) and (gnomAD_ge_AF_EAS < "$1" or not gnomAD_ge_AF_EAS) and (gnomAD_ge_AF_FIN < "$1" or not gnomAD_ge_AF_FIN) and (gnomAD_ge_AF_NFE < "$1" or not gnomAD_ge_AF_NFE) and (gnomAD_ge_AF_SAS < "$1" or not gnomAD_ge_AF_SAS) and (AA_AF < "$1" or not AA_AF) and (EA_AF < "$1" or not EA_AF) and ((IMPACT is HIGH) or (IMPACT is MODERATE) or (IMPACT is LOW) or (SpliceAI_SYMBOL)) and (gnomAD_ex_nhomalt < 5 or not gnomAD_ex_nhomalt)) or (ClinVar_CLNSIG and not (ClinVar_CLNSIG match benign or ClinVar_CLNSIG match Benign)) or (CLIN_SIG match pathogenic or CLIN_SIG match Pathogenic)"
		}}
		
		filter_vep_str="$(return_AF_string_w_genomes 0.02)"
		echo "bcftools +fill-tags {input} -- -t AN,AC | filter_vep --format vcf --force_overwrite --filter \\""$filter_vep_str"\\" | bgzip > {output}" | bash
		"""



rule PrefilteredVEP_ToTSV:
	input:
		"results/filtering/annotated_split_vep_{contig}.vcf.gz"
	output:
		"results/filtering/annotated_split_vep_{contig}.tsv"
	params:
		partition=config["long"],
		vep_renamed="results/filtering/annotated_filtered_renamed_{contig}.vcf.gz",
		anno_sources=config["database_dir"],
	conda:
		"envs/vep_101.yaml"
	resources: cpus=1, mem_mb=9000, time_job=10040
	shell:
		"""
		
		zcat {input} | sed 's:;AN=:;AN_cohort=:g' | \
		sed 's:ID=AN,:ID=AN_cohort,:g' | \
		sed 's:;AC=:;AC_cohort=:g' | \
		sed 's:ID=AC,:ID=AC_cohort,:g' | \
		sed 's:||:|0|:g'| sed 's:||:|0|:g' | bgzip > {params.vep_renamed}
		
		split_string1='%CHROM\\t%POS\\t%ID\\t%REF\\t%ALT\\t%QUAL\\t%AC_cohort\\t%AN_cohort\\t'
		split_string2='%CSQ\\t'
		split_string3='[%GT\\t%TGT\\t%AD\\t%GQ\\t]' # 

		header1=$(echo $split_string1 | sed 's:\\\\t:	:g')
		header2=$(bcftools +split-vep {params.vep_renamed} -l -l | cut -f2 | tr "\\n" "\\t")
		header3=$(bcftools query -u -H -f $split_string3'\\n' {params.vep_renamed} | head -n1 | cut -f2-5) ||  echo ""
		echo "sample	${{header1}}	$header2	$header3" | awk -v OFS="\\t" '$1=$1'  > {output}
		for sample in `bcftools query -l {params.vep_renamed}`; do
			bcftools view -c1 -s $sample {params.vep_renamed}  | \
			bcftools +split-vep -f $split_string1$split_string2$split_string3'\\n' -d -A tab | \
			awk -v var="$sample"  -F $'\t' 'BEGIN {{OFS = FS}} {{print var, $0 }}' >> {output}
		done
		#rm -f {params.vep_renamed}
		"""



rule ReformatVEP_For_RVAS:
	input:
		"results/vep/annotated_{contig}.vcf.gz"
	output:
		"results/for_RVAS/annotated_split_vep_{contig}.tsv"
	params:
		partition=config["medium"],
	conda:
		"envs/bcftools_plink_R_bedtools.yaml"
	resources: cpus=1, mem_mb=9000, time_job=1400
	shell:
		"""
		bcftools +split-vep -l {input} | cut -f2 | tr '\\n' ';' | awk 'BEGIN {{ FS = ";"}} ;{{ print "ID;"$0}}' > {output}
		bcftools +split-vep -d -f'%CHROM:%POS:%REF:%ALT;%CSQ\n' -A ";" {input} >> {output}
		"""


rule MakeRegenieAnnoFiles:
	input:
		"results/for_RVAS/annotated_split_vep_{contig}.tsv"
	output:
		"results/for_RVAS/{contig}.anno.file.txt",
		"results/for_RVAS/{contig}.aaf.file.txt",
		"results/for_RVAS/{contig}.set.list.txt",
		"results/for_RVAS/{contig}.vars_cat.tsv",
	resources: cpus=1, mem_mb=18000, time_job=720
	params:
		partition=config["medium"]
	conda:
		"envs/bcftools_plink_R_bedtools.yaml"
	script:
		"scripts/make_aaf_anno.R"


rule MergeRegenieAnnoFiles:
	input:
		expand("results/for_RVAS/{contig}.{filetype}.txt",contig=config["contigs"], allow_missing=True)
	output:
		"results/for_RVAS/all_contigs_{filetype}.txt"
	resources: cpus=1, mem_mb=18000, time_job=720
	params:
		partition=config["medium"]
	conda:
		"envs/bcftools_plink_R_bedtools.yaml"
	shell:
		"cat {input} > {output}"




rule GetMAF_GnomAD3_ForQC:
	input:
		"results/vep/annotated_{contig}.vcf.gz"
	output:
		"results/maf_comp/afs_{contig}.tsv.gz"
	resources: cpus=1, mem_mb=18000, time_job=720
	params:
		partition=config["medium"]
	conda:
		"envs/bcftools_plink_R_bedtools.yaml"
	shell:
		"""
		bcftools view --min-ac 1 {input} | \
		bcftools +fill-tags | \
		bcftools +split-vep -f "%CHROM\t%ID\t%MAF\t%AN\t%gnomAD_ge_AF\t%gnomAD_ge_AF_nfe\t%gnomAD_ge_AC\n" --select worst:any |
		gzip > {output}
		"""

# END # ANNOTATION ####################################################################################################################################



# START # RVTESTS #####################################################################################################################################

rule dev_test_rvtest:
        input:
                expand("results/rvtests/results_Fisher/EUR_POP_{pheno}/{mask}_{af_cutoff}.CMCFisherExact.assoc",
                pheno=config["phenotypes"],mask=config["masks"], af_cutoff=config["af_cutoffs"]),
#                expand("results/rvtests/results_EUR_POP_{pheno}/{mask}_{af_cutoff}.Skat.assoc",
#                pheno=config["phenotypes"],mask=config["masks"], af_cutoff=config["af_cutoffs"]),
                #vcf_out="results/rvtests/var_subsets/M3_0.01.vcf.gz",
                #out_file="results/rvtests/results/M3_0.01.Skat.assoc",
        resources: cpus=4, mem_mb=16000, time_job=720
        params:
                partition=config["medium"],


rule CalcFreqPlink:
        input:
                fam="results/var_sets/EURs_unrel/general.fam",
                bim="results/var_sets/EURs_unrel/general.bim",
                bed="results/var_sets/EURs_unrel/general.bed",
        output:
                data_af_file="results/RVAS/plink_freq.afreq",
                data_ac_file="results/RVAS/plink_freq.acount",
        resources: cpus=4, mem_mb=64000, time_job=720
        params:
                partition=config["medium"],
                plink_in_prefix=lambda wildcards, input: input.fam[:-4],
                freq_out_prefix=lambda wildcards, output: output.data_af_file[:-6],
                ac_out_prefix=lambda wildcards, output: output.data_ac_file[:-7],
        conda:
                "envs/bcftools_plink_R.yaml"
        shell:
                """
                plink2 --bfile {params.plink_in_prefix} --freq --out {params.freq_out_prefix}
                plink2 --bfile {params.plink_in_prefix} --freq counts --out {params.ac_out_prefix}
                """

rule MergeAafFilesDataAnno:
        input:
                data_af_file="results/RVAS/plink_freq.afreq",
                data_ac_file="results/RVAS/plink_freq.acount",
                regenie_aaf_file="results/for_RVAS/all_contigs_aaf.file.txt",
        output:
                data_anno_aaf_file="results/RVAS/data.anno.aaf.file.txt"
        resources: cpus=4, mem_mb=32000, time_job=720
        params:
                partition=config["medium"],
        run:
                import pandas as pd
                import numpy as np
                data_af = pd.read_csv(input.data_af_file, sep="\s+")
                data_af=data_af[["ID","ALT_FREQS"]]
                anno_af = pd.read_csv(input.regenie_aaf_file, sep=" ", names=["snp", "aaf"])
                joined = data_af.join(anno_af.set_index("snp"), on="ID", how="inner")
                joined["merged_aaf"] = joined[["ALT_FREQS", "aaf"]].max(axis=1)
                
                # added AC check - however - this is not effective with the current sample size)
                data_ac = pd.read_csv(input.data_ac_file, sep="\s+")
                data_ac=data_ac[["ID","ALT_CTS"]]
                joined_AC=joined.join(data_ac.set_index("ID"), on="ID", how="inner")
                joined_AC["merged_aaf"] = np.where( (joined_AC.ALT_CTS > 2) & (joined_AC.merged_aaf<0.001), 0.005, joined_AC.merged_aaf)
                joined_AC.merged_aaf = joined_AC.merged_aaf.round(4)
                joined_AC[["ID", "merged_aaf"]].to_csv(output.data_anno_aaf_file, sep=" ", header=False, index=False, float_format='%.5E')



rule plink_subset_for_rvtest:
        input:
                fam="results/var_sets/EURs_unrel/general.fam",
                bim="results/var_sets/EURs_unrel/general.bim",
                bed="results/var_sets/EURs_unrel/general.bed",
                regenie_anno_file="results/for_RVAS/all_contigs_anno.file.txt",
                data_anno_aaf_file="results/RVAS/data.anno.aaf.file.txt",
#                regenie_aaf_file="results/for_RVAS/all_contigs_aaf.file.txt",
                regenie_mask_def="resources/mask_definition.mask",
        output:
                expand("results/rvtests/var_subsets/{mask}_{af_cutoff}.{suffix}",
                mask=config["masks"], af_cutoff=config["af_cutoffs"],
                suffix=["fam", "bim", "bed"]),
                setFile_rvtest="results/rvtests/rvtest_setFile.tsv",
                debug_joined_out="results/rvtests/debug_joined_out.tsv"
        resources: cpus=4, mem_mb=32000, time_job=720
        params:
                partition=config["medium"],
                plink_in_prefix=lambda wildcards, input: input.fam[:-4],
                plink_out_folder="results/rvtests/var_subsets/",
                masks=config["masks"],
                af_cutoffs=config["af_cutoffs"],
        conda: "envs/pandas_plink.yaml"
        script: "scripts/plink_subset_for_rvtest.py"

rule plink_subset_to_vcf_for_rvtest:
        # Split the vcf, extract all variants specified
        # TODO remove the --chr 21 constraint in plink2 comand (now there for performance reasons)
        input:
                fam="results/rvtests/var_subsets/{mask}_{af_cutoff}.fam",
                bim="results/rvtests/var_subsets/{mask}_{af_cutoff}.bim",
                bed="results/rvtests/var_subsets/{mask}_{af_cutoff}.bed",
        output:
                vcf_out="results/rvtests/var_subsets/{mask}_{af_cutoff}.vcf.gz",
        resources: cpus=4, mem_mb=16000, time_job=720
        params:
                partition=config["medium"],
                plink_in_prefix=lambda wildcards, input: input.fam[:-4],
                vcf_out_prefix=lambda wildcards, output: output.vcf_out[:-7],
        conda:
                "envs/bcftools_plink_R.yaml"
        shell:
                """
                plink2 --bfile {params.plink_in_prefix} --export vcf bgz id-paste=iid --out {params.vcf_out_prefix} --allow-extra-chr
                bcftools index -f -t {params.vcf_out_prefix}.vcf.gz
                """


rule pheno_file_for_rvtest:
        input:
                fam="results/var_sets/EURs_unrel/general.fam",
                phenotypes="results/var_sets/EURs_unrel/{pheno}/common.pheno",
        output:
                rvtest_pheno_file="results/rvtests/pheno_EUR_{pheno}.tsv",
        resources: cpus=4, mem_mb=16000, time_job=720
        params:
                partition=config["medium"],
        run:
                import pandas as pd
                fam = pd.read_csv(input.fam, names=["fid", "iid","fatid","matid","sex","empty"], sep=' ')
                pheno = pd.read_csv(input.phenotypes, names=["fid","iid","pheno"], sep='\t', header=0).set_index("iid")
                pheno.head()
                out = fam.join(pheno.pheno, on="iid")
                out.pheno = out.pheno + 1
                out[["fid", "iid","fatid","matid","sex","pheno"]].to_csv(output.rvtest_pheno_file, sep="\t", header=False, index=False)

rule rvtest_SKAT:
        input:
                invcf="results/rvtests/var_subsets/{mask}_{af_cutoff}.vcf.gz",
                fam="results/var_sets/EURs_unrel/general.fam",
                setFile_rvtest="results/rvtests/rvtest_setFile.tsv",
                rvtest_pheno_file="results/rvtests/pheno_{population}_{pheno}.tsv",
#                covar_file="covariates.cov",
        output:
                out_file="results/rvtests/results_SKAT/{population}_POP_{pheno}/{mask}_{af_cutoff}.Skat.assoc",
        resources: cpus=4, mem_mb=16000, time_job=720
        params:
                partition=config["medium"],
                out_prefix=lambda wildcards, output: output.out_file[:-11],
        conda:
                "envs/rvtests.yaml"
        shell:
                """
                rvtest \
                --inVcf {input.invcf} \
                --pheno {input.rvtest_pheno_file} \
                --setFile {input.setFile_rvtest} \
                --noweb \
                --kernel skat \
                --out {params.out_prefix}
                """


rule rvtest_fisher:
        input:
                invcf="results/rvtests/var_subsets/{mask}_{af_cutoff}.vcf.gz",
                fam="results/var_sets/EURs_unrel/general.fam",
                setFile_rvtest="results/rvtests/rvtest_setFile.tsv",
                rvtest_pheno_file="results/rvtests/pheno_{population}_{pheno}.tsv",
#                covar_file="covariates.cov",
        output:
                out_file="results/rvtests/results_Fisher/{population}_POP_{pheno}/{mask}_{af_cutoff}.CMCFisherExact.assoc",
        resources: cpus=4, mem_mb=16000, time_job=720
        params:
                partition=config["medium"],
                out_prefix=lambda wildcards, output: output.out_file[:-21],
        conda:
                "envs/rvtests.yaml"
        shell:
                """
                rvtest \
                --inVcf {input.invcf} \
                --pheno {input.rvtest_pheno_file} \
                --setFile {input.setFile_rvtest} \
                --noweb \
                --burden exactCMC \
                --out {params.out_prefix}
                """

_ = """
                --pheno-name target \
                --covar {input.covar_file} \
                --covar-name sex,age,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10 \
"""





# END # RVTESTS #####################################################################################################################################
# START # REGIONAL TESTS #####################################################################################################################################




rule rvtest_SKAT_regional:
        input:
                invcf="results/var_sets/EURs_unrel/general.vcf.bgz",
                fam="results/var_sets/EURs_unrel/general.fam",
                setFile_rvtest="results/rvtests/regional_rvtest_setFile.tsv",
                rvtest_pheno_file="results/rvtests/pheno_{population}_{pheno}.tsv",
#                covar_file="covariates.cov",
        output:
                out_file="results/rvtests/results_SKAT_regional/{population}_POP_{pheno}/{mask}_{af_cutoff}.Skat.assoc",
        resources: cpus=4, mem_mb=16000, time_job=720
        params:
                partition=config["medium"],
                out_prefix=lambda wildcards, output: output.out_file[:-11],
        conda:
                "envs/rvtests.yaml"
        shell:
                """
                rvtest \
                --inVcf {input.invcf} \
                --pheno {input.rvtest_pheno_file} \
                --setFile {input.setFile_rvtest} \
                --noweb \
                --kernel skat \
                --out {params.out_prefix}
                """


# END # REGIONAL TESTS #####################################################################################################################################
# START # GENOME SCANNING #####################################################################################################################################

rule GenomeScan:
        input:
                phenofam="results/rvtests/pheno_{population}_{pheno}.tsv",
                bim="results/var_sets/EURs_unrel/general.bim",
                bed="results/var_sets/EURs_unrel/general.bed",
                temp="resources/GECS_template.param",
        output:
                fam="results/genomeScan/genomeScan{population}_{pheno}G.fam",
        resources: cpus=4, mem_mb=64000, time_job=720
        params:
                partition=config["medium"],
                out_dir="results/genomeScan",
                out_prefix="results/genomeScan/genomeScan{population}_{pheno}"
        conda:
                "envs/bcftools_plink_R.yaml"
        shell:
                """
                cp -f {input.phenofam} {params.out_prefix}G.fam
                cp -f {input.bim} {params.out_prefix}G.bim
                cp -f {input.bed} {params.out_prefix}G.bed

                cp {input.temp} {params.out_prefix}.param
                
                sed -i "s:bfile:{params.out_prefix}G:g" {params.out_prefix}.param
                sed -i "s:outx:{params.out_prefix}:g" {params.out_prefix}.param
                
                resources/.no_upload/GECS/gecs {params.out_prefix}.param

                rm -f {params.out_prefix}G.b*
                """




# END # GENOME SCANNING #####################################################################################################################################





# START # OLD / ARRAY based QC #####################################################################################################################################






rule extract_dbSNP_file:
	input:
		"resources/.no_upload/dbSNP_hg38_pos_chr18_dedup.txt.gz"
	output:
		pos="results/array_comparison/dbSNP_pos.txt",
		ids="results/array_comparison/dbSNP_ids.txt",
	resources: cpus=1, mem_mb=4000, time_job=720
	params:
		partition=config["medium"],
	shell:
		"""
		zcat {input} > {output.pos}
		zcat {input} | cut -f1 -d" " > {output.ids}
		"""
rule rename_plink_array:
	input:
		arrayfam=config["array_files"],
		dbSNP_ids="results/array_comparison/dbSNP_ids.txt",
		dbSNP_pos="results/array_comparison/dbSNP_pos.txt"
	output:	
		array_fam="results/array_comparison/array_local.fam",
	resources: cpus=2, mem_mb=16000, time_job=2880
	params:
		partition=config["long"],
		ar_pl_in=lambda wildcards, input: input["arrayfam"][:-4],
		ar_pl_out=lambda wildcards, output: output["array_fam"][:-4],
	conda: "spark"
	shell:
		"""
		plink \
		 --bfile "{params.ar_pl_in}" \
		 --extract "{input.dbSNP_ids}" \
		 --make-bed \
		 --out {params.ar_pl_out}_tmp1
		
		plink \
		 --bfile {params.ar_pl_out}_tmp1 \
		 --update-map "{input.dbSNP_pos}" 3 1 \
		 --make-bed \
		 --out {params.ar_pl_out}
		
		awk '{{print $2"ARRAY",$2"ARRAY",$3,$4,$5,$6}}' {params.ar_pl_out}.fam > {params.ar_pl_out}_tmp.fam

		mv {params.ar_pl_out}_tmp.fam {params.ar_pl_out}.fam
		rm -f {params.ar_pl_out}_tmp*
		"""

rule make_plink_seq_data:
	input:
		vcf="results/normalized/df3_norm.vcf.gz",
		array_fam="results/array_comparison/array_local.fam",
		dbSNP_pos="results/array_comparison/dbSNP_pos.txt"
	output:
		allplink="results/array_comparison/seq.fam"
	resources: cpus=4, mem_mb=20000, time_job=2880
	params:
		partition=config["long"],
		plink_pref=lambda wildcards, output: output["allplink"][:-4],
		array_plink=lambda wildcards, input: input["array_fam"][:-4],
	conda: "envs/bcftools_plink_R.yaml"
	shell:
		"""
		echo "start"
		
		plink \
		 --vcf {input.vcf} \
		 --chr 18,19,20,21 \
		 --vcf-half-call h \
		 --double-id \
		 --make-bed \
		 --out {params.plink_pref}_tmp
		
		plink \
		--bfile {params.plink_pref}_tmp \
		--update-name "{input.dbSNP_pos}" 1 4 \
		--make-just-bim \
		--out {params.plink_pref}_tmp2
		
		cat {params.plink_pref}_tmp2.bim | sed "s/chr//g" > {params.plink_pref}_tmp.bim
		

		plink \
		--fam {params.plink_pref}_tmp.fam \
		--bed {params.plink_pref}_tmp.bed \
		--bim {params.plink_pref}_tmp.bim \
		--extract {params.array_plink}.bim \
		--make-bed \
		--out {params.plink_pref}
		
		rm -f {params.plink_pref}_tmp*
		""" 
		


rule compare_w_array_king:
	input:
		array_fam="results/array_comparison/array_local.fam",
		sequencing_fam="results/array_comparison/seq.fam",
	output:	
		kinship_vals="results/array_comparison/array_comp.con",
	resources: cpus=4, mem_mb=32000, time_job=720
	params:
		partition=config["medium"],
		hl_pl=lambda wildcards, input: input["sequencing_fam"][:-4],
		ar_pl=lambda wildcards, input: input["array_fam"][:-4],
		king_prefix=lambda wildcards, output: output["kinship_vals"][:-4],
		
	conda: "envs/king.yaml"
	shell:
		"""
		#module load king
	
		king \
		-b {params.hl_pl}.bed,{params.ar_pl}.bed \
		--duplicate \
		--related \
		--degree 1 \
		--prefix {params.king_prefix}
		
		king \
		-b {params.hl_pl}.bed,{params.ar_pl}.bed \
		--kinship \
		--prefix {params.king_prefix}_kinship
		
		"""



rule Regenie_step1:
	input:
		pathCov="results/regenie_pheno/cov_{population}_{pheno}.cov",
		pathPheno="results/regenie_pheno/pheno_{population}_{pheno}.pheno", 
		filtered="results/regenie/pheno_{population}_{pheno}_pruned_plink.txt",
		fam="results/var_sets/for_QC/common_pruned.fam",
		bim="results/var_sets/for_QC/common_pruned.bim",
		bed="results/var_sets/for_QC/common_pruned.bed",
	output:
		step1="results/regenie/pheno_{population}_{pheno}_step1_pred.list"
	resources: cpus=1, mem_mb=18000, time_job=720
	conda: "envs/regenie.yaml"
	params:
		partition=config["medium"],
		plink_file=lambda wildcards, input: input["fam"][:-4],
		step1=lambda wildcards, output: output["step1"][:-10],
	shell:
		"""
		#export LD_LIBRARY_PATH={config[LD_LIBRARY_PATH]}
		
		regenie \
		  --step 1 \
		  --bed {params.plink_file} \
		  --covarFile {input.pathCov} \
		  --phenoFile {input.pathPheno} \
		  --bt \
		  --extract {input.filtered} \
		  --loocv \
		  --bsize 1000 \
		  --out {params.step1}
		#--extract input.pruned \
		 """


rule make_pheno_cov_saige:
	input:
		pathCov="results/regenie_pheno/cov_{population}_{pheno}.cov",
		pathPheno="results/regenie_pheno/pheno_{population}_{pheno}.pheno", 
	output:
		"results/regenie_pheno/cov_{population}_{pheno}.phenocov",
		"results/regenie_pheno/cov_{population}_{pheno}.males",
	resources: cpus=1, mem_mb=18000, time_job=720
	params:
		partition=config["medium"],
	conda: "envs/bcftools_plink_R.yaml"
	script: "scripts/make_phenoCov.R"


rule get_plink_step1:
	input:
		keep_fam="results/regenie_pheno/fam_{population}_{pheno}.fam",
		fam="results/var_sets/for_QC/common_pruned.fam",
		bim="results/var_sets/for_QC/common_pruned.bim",
		bed="results/var_sets/for_QC/common_pruned.bed",
		longrange_LD="resources/regions_longrange_LD_GRCh38.txt",
	output:
		fam="results/regenie/pheno_{population}_{pheno}_pruned_plink.fam",
		bim="results/regenie/pheno_{population}_{pheno}_pruned_plink.bim",
		bed="results/regenie/pheno_{population}_{pheno}_pruned_plink.bed",
		var_ids="results/regenie/pheno_{population}_{pheno}_pruned_plink.txt",
	resources: cpus=1, mem_mb=10000, time_job=720
	params:
		partition=config["medium"],
		pruned_plink=lambda wildcards, output: output["bim"][:-4],
	conda: "envs/bcftools_plink_R.yaml"
	shell:
		"""
		# LD pruned variants for regenie step 1
		plink \
		--bed {input.bed} \
		--bim {input.bim} \
		--fam {input.fam} \
		--keep {input.keep_fam} \
		--maf 0.01 \
		--chr 1-22 \
		--geno 0.01 \
		--snps-only just-acgt \
		--hwe 1e-10 \
		--exclude range {input.longrange_LD} \
		--make-bed \
		--out {params.pruned_plink}
		
		cut -f2 {output.bim} > {output.var_ids}
		
		"""


rule SAGE_step1:
	input:
		phenocov="results/regenie_pheno/cov_{population}_{pheno}.phenocov",
		fam="results/regenie/pheno_{population}_{pheno}_pruned_plink.fam",
		bim="results/regenie/pheno_{population}_{pheno}_pruned_plink.bim",
		bed="results/regenie/pheno_{population}_{pheno}_pruned_plink.bed",
	output:
		step1="results/saige/pheno_{population}_{pheno}.rda"
	resources: cpus=1, mem_mb=18000, time_job=720
	conda: "envs/saige.yaml"
	params:
		partition=config["medium"],
		plink_file=lambda wildcards, input: input["fam"][:-4],
		step1=lambda wildcards, output: output["step1"][:-4],
	shell:
		"""
		step1_fitNULLGLMM.R \
		--plinkFile={params.plink_file} \
		--phenoFile={input.phenocov} \
		--phenoCol={wildcards.pheno} \
		--covarColList=PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,Age,Age2,age_sex,sex_for_fam \
		--sampleIDColinphenoFile=IID \
		--traitType=binary \
		--outputPrefix={params.step1} \
		--LOCO=TRUE \
		--IsOverwriteVarianceRatioFile=TRUE \
		--nThreads=4
		"""

rule make_saige_vcf_from_plink:
	input:
		bed="results/additional_QC/{population}_{pheno}/not_rel_QCed.bed",
		bim="results/additional_QC/{population}_{pheno}/not_rel_QCed.bim",
		fam="results/additional_QC/{population}_{pheno}/not_rel_QCed.fam"
	output:
		vcf="results/additional_QC/{population}_{pheno}/not_rel_QCed.vcf.gz",
		vcf_justX="results/additional_QC/{population}_{pheno}/not_rel_QCed_justX.vcf.gz",
	resources: cpus=1, mem_mb=18000, time_job=720
	params:
		partition=config["medium"],
		vcfprefix=lambda wildcards, output: output["vcf"][:-7],
		vcfprefix_justX=lambda wildcards, output: output["vcf_justX"][:-7],
		plink_in=lambda wildcards, input: input["fam"][:-4],
	conda: "envs/bcftools_plink_R.yaml"
	shell:
		"""
		plink \
		--bfile {params.plink_in} \
		--recode vcf-iid \
		--out {params.vcfprefix}
		
		cat  {params.vcfprefix}.vcf | bgzip > {output.vcf}
		tabix --csi -pvcf {output.vcf}

		plink \
		--bfile {params.plink_in} \
		--recode vcf-iid \
 		--chr X \
		--out {params.vcfprefix_justX}

 		cat  {params.vcfprefix_justX}.vcf | bgzip > {output.vcf_justX}
 		tabix --csi -pvcf {output.vcf_justX}
		
		"""

rule SAIGE_step2_GWAS:
	input:
		pathCov="results/regenie_pheno/cov_{population}_{pheno}.cov",
		pathPheno="results/regenie_pheno/pheno_{population}_{pheno}.pheno",
		step1="results/saige/pheno_{population}_{pheno}.rda",
		vcf="results/additional_QC/{population}_{pheno}/not_rel_QCed.vcf.gz",
		vcf_justX="results/additional_QC/{population}_{pheno}/not_rel_QCed_justX.vcf.gz",
		males="results/regenie_pheno/cov_{population}_{pheno}.males",
	output:
		path_saige="results/saige/{chrom}GWAS_{population}_{pheno}.saige.txt"
	resources: cpus=1, mem_mb=18000, time_job=720
	conda: "envs/saige.yaml"
	params:
		partition=config["medium"],
		saige_step1=lambda wildcards, input: input["step1"][:-4],
		in_vcf=lambda wildcards, input: input["vcf_justX"] if (str(wildcards["chrom"])=="23") else input["vcf"],
		loco=lambda wildcards, input: "--LOCO=TRUE --chrom=" + str(wildcards["chrom"]) if (str(wildcards["chrom"])!="23") else "--LOCO=FALSE --chrom=23 --X_PARregion=10001-2781479,155701383-156030895 --sampleFile_male="+input["males"]+" --is_rewrite_XnonPAR_forMales=TRUE",
	shell:
		"""
		
		step2_SPAtests.R \
		--vcfField=GT \
		--GMMATmodelFile={params.saige_step1}.rda \
		--varianceRatioFile={params.saige_step1}.varianceRatio.txt \
		--SAIGEOutputFile={output} \
		--numLinesOutput=1000 \
		--IsOutputNinCaseCtrl=TRUE \
		--IsOutputHetHomCountsinCaseCtrl=TRUE \
		--minMAC=3 \
		--IsOutputAFinCaseCtrl=TRUE \
		--vcfFile={params.in_vcf} {params.loco}	

		"""

rule merge_saige_GWAS:
	input:
		expand("results/saige/{chrom}GWAS_{population}_{pheno}.saige.txt", chrom=config["contigs_wo_X"]+[23], allow_missing=True)
	output:
		path_saige="results/saige/allChrGWAS_{population}_{pheno}.saige.txt.gz"
	resources: cpus=1, mem_mb=18000, time_job=720
	params:
		header="results/saige/GWAS_{population}_{pheno}_header.txt",
		partition=config["medium"],
	shell:
		"""
		if cat {input} | grep "CHR" | head -n1 > {params.header}
		then
		echo "don't worry"
		fi

		cat {input} | grep -v "CHR" | \
		cat {params.header} - |
		gzip > {output}
		"""

rule ApplyRelatednessFilter:
	input:
		GWAS_MT="results/prune_filter/filtered",
		pheno_file="results/hail_gather_data/for_sample_QC.tsv"
	output:		
		kinship_vals="results/kinship/hail_kinship_coefficients.tsv",
		to_remove="results/kinship/relatives_to_remove.tsv",
	resources: cpus=8, mem_mb=80000, time_job=2880, additional=" --ntasks=1 -x " + config["master_nodes_excluded"] #--gres localtmp:300G 
	params:
		partition=config["long"],
		tmp_dir=config["tmp_folder"] +"kinship/",
	conda: "spark"
	shell:
		"""	
		mkdir -p {params.tmp_dir}
		
		hail_python_script="workflow/scripts/relatedness_filter.py $(pwd)/{input.GWAS_MT} $(pwd)/{params.tmp_dir} $(pwd)/{input.pheno_file} $(pwd)/{output.kinship_vals} $(pwd)/{output.to_remove}"
		
		if [ {config[cluster]} = "yes" ]; then
		queue="long"
		hours_to_run=168
		DRIVE_MEM=78
		worker_nodes_excluded={config[worker_nodes_excluded]}
		num_workers=20
		source workflow/scripts/spark_submit_command.sh
		$spark_submit_command $hail_python_script
		
		else
		python $hail_python_script
		fi
		
		rm -rf {params.tmp_dir}*
		"""
